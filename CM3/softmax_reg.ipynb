{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A (slow) implementation of softmax regression\n",
    "\n",
    "To first understand how everything works, we do not vectorize the operations yet (this will be the topic of TP 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_fmnist import TEXT_LABELS, load_images, load_labels\n",
    "import time\n",
    "\n",
    "IN_DIM, OUT_DIM = 784, 10\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def show(n, width=300):\n",
    "    import plotly.express as px\n",
    "    fig = px.imshow(train_imgs[n], binary_string=True, width=width, title=TEXT_LABELS[train_labels[n]])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = load_images()\n",
    "train_labels = load_labels()\n",
    "val_imgs = load_images(test=True)\n",
    "val_labels = load_labels(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(5, width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure data has the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_flat = train_imgs.reshape(len(train_imgs), -1)\n",
    "val_imgs_flat = val_imgs.reshape(len(val_imgs), -1)\n",
    "assert train_imgs_flat.shape == (60000, 784) and val_imgs_flat.shape == (10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define softmax, cross entropy loss, initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(o):\n",
    "    o_exp = np.exp(o - np.max(o)) # for numeric stability\n",
    "    return o_exp / np.sum(o_exp)\n",
    "\n",
    "def cross_entropy_loss(p, c):\n",
    "    return -np.log(p[c] + 1e-15)\n",
    "\n",
    "def initialize(sigma=0.01):\n",
    "    return np.random.normal(0, sigma, (IN_DIM, OUT_DIM)), np.zeros(OUT_DIM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x, probs, label):\n",
    "    probs_copy = probs.copy()\n",
    "    probs_copy[label] -= 1\n",
    "    return np.outer(x.T, probs_copy), probs_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(lr=0.01, num_epochs=10, sigma=0.01, batch_size=64, W=None, b=None, verbose=False):\n",
    "    print(f\"Training softmax regression with SGD, {lr=}, {batch_size=}, {num_epochs=}, non-vectorized version\")\n",
    "\n",
    "    if W is None: W, b = initialize(sigma=sigma)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t0 = time.time()\n",
    "        loss = 0\n",
    "        num_batches = len(train_imgs_flat) // batch_size\n",
    "        for batch_imgs, batch_labels in create_batches(train_imgs_flat, train_labels, batch_size):\n",
    "            grad_W, grad_b = np.zeros_like(W), np.zeros_like(b)\n",
    "            for x, label in zip(batch_imgs, batch_labels):\n",
    "                probs = softmax(x @ W + b)\n",
    "                loss += cross_entropy_loss(probs, label) / batch_size\n",
    "                grad_W_sample, grad_b_sample = grad(x, probs, label)\n",
    "                grad_W += grad_W_sample / batch_size\n",
    "                grad_b += grad_b_sample / batch_size\n",
    "            W -= lr * grad_W\n",
    "            b -= lr * grad_b\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}, avg loss per batch: {loss / num_batches}, time: {(time.time() - t0):3f}\")\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating random batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, labels, batch_size):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    N = len(indices)\n",
    "    indices = indices[:(N // batch_size) * batch_size]\n",
    "    for s in range(0, len(indices), batch_size):\n",
    "        batch_indices = indices[s:s + batch_size]\n",
    "        yield data[batch_indices], labels[batch_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = train_sgd(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(W, b, ims, ys):\n",
    "    correct = 0\n",
    "    for x, y in zip(ims,ys):\n",
    "        pred = np.argmax(softmax(x @ W + b))\n",
    "        if pred == y:\n",
    "            correct += 1\n",
    "    return correct / len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = evaluate(W, b, val_imgs_flat, val_labels)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2%}\")\n",
    "assert val_accuracy > .8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
